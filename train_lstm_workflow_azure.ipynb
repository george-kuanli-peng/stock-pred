{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Workflow in Azure Machine Learning\r\n",
        "\r\n",
        "## Preparation\r\n",
        "\r\n",
        "1. Download the workspace config file `config.json` from the Azure ML Workspace page\r\n",
        "   and save it in the same or parent directories.\r\n",
        "   This will be used in connecting to the workspace.\r\n",
        "1. Make sure the training data is avilable in Azure ML Data Asset,\r\n",
        "   or download a new version and save it in the `data/` directory.\r\n",
        "1. Make sure a compute target is avilable in Azure ML Workspace.\r\n",
        "\r\n",
        "Ref: [Tutorial: Create production ML pipelines with Python SDK v2 (preview) in a Jupyter notebook](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-pipeline-python-sdk)\r\n",
        "\r\n",
        "## Global configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Data registration\r\n",
        "To upload new data, set REGISTER_DATA to True, DATA_VER to a new value.\r\n",
        "Otherwise, set REGISTER_DATA to False, DATA_VER to an existing value.\r\n",
        "\"\"\"\r\n",
        "REGISTER_DATA = False\r\n",
        "DATA_NAME = 'stock_prices'\r\n",
        "DATA_VER = '1'\r\n",
        "DATA_UPLOAD_PATH = './data/'\r\n",
        "\r\n",
        "\"\"\" Compute target\r\n",
        "\"\"\"\r\n",
        "COMPUTE_TARGET_NAME = 'george-mlops-compute-cluster'\r\n",
        "\r\n",
        "\"\"\" Environment\r\n",
        "To create environment, set REGISTER_ENV to True, ENV_VER to a new value.\r\n",
        "Otherwise, set REGISTER_ENV to False, ENV_VER to an existing value.\r\n",
        "\"\"\"\r\n",
        "REGISTER_ENV = False\r\n",
        "ENV_NAME = 'tensorflow_sklean_cpu'\r\n",
        "ENV_VER = '1.0'\r\n",
        "\r\n",
        "\"\"\" Scaler & model\r\n",
        "\"\"\"\r\n",
        "# WINDOW=50\r\n",
        "# TEST_RATIO=0.2\r\n",
        "SCALER_FILE_NAME = 'scaler.pkl'\r\n",
        "TRAIN_DATA_X_FILE_NAME = 'x_train.npy'\r\n",
        "TRAIN_DATA_Y_FILE_NAME = 'y_train.npy'\r\n",
        "TEST_DATA_X_FILE_NAME = 'x_test.npy'\r\n",
        "TEST_DATA_Y_FILE_NAME = 'y_test.npy'\r\n",
        "\r\n",
        "\"\"\" Pipeline & experiment\r\n",
        "\"\"\"\r\n",
        "EXPERIMENT_NAME = 'stock-pred-model-train'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655368506318
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to the workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import MLClient\r\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\r\n",
        "\r\n",
        "try:\r\n",
        "    credential = DefaultAzureCredential()\r\n",
        "    # Check if given credential can get token successfully.\r\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\r\n",
        "except Exception as ex:\r\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\r\n",
        "    credential = InteractiveBrowserCredential()\r\n",
        "\r\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655368509241
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Data\r\n",
        "from azure.ai.ml.constants import AssetTypes\r\n",
        "\r\n",
        "if REGISTER_DATA:\r\n",
        "    train_data = Data(\r\n",
        "        name=DATA_NAME,\r\n",
        "        version=DATA_VER,\r\n",
        "        description='Stock market prediction training data',\r\n",
        "        type=AssetTypes.URI_FOLDER,\r\n",
        "        path=DATA_UPLOAD_PATH\r\n",
        "    )\r\n",
        "\r\n",
        "    train_data = ml_client.data.create_or_update(train_data)\r\n",
        "    print(\r\n",
        "        f'Dataset with name {train_data.name} was registered to workspace, '\r\n",
        "        f'the dataset version is {train_data.version}'\r\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655368511360
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get a compute resource to run pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_cluster = ml_client.compute.get(COMPUTE_TARGET_NAME)\r\n",
        "print(f'Compute target {COMPUTE_TARGET_NAME} found')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655368516427
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create or get a job environment to run pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\r\n",
        "\r\n",
        "if REGISTER_ENV:\r\n",
        "    my_env = Environment(\r\n",
        "        name=ENV_NAME,\r\n",
        "        version=ENV_VER,\r\n",
        "        description='TensorFlow 2.x and scikit-learn 1.x on CPU',\r\n",
        "        conda_file='./env_azure.yml',\r\n",
        "        image='mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest'\r\n",
        "    )\r\n",
        "\r\n",
        "    my_env = ml_client.environments.create_or_update(my_env)\r\n",
        "\r\n",
        "    print(\r\n",
        "        f'Environment with name {my_env.name} is registered to workspace, '\r\n",
        "        f'the environment version is {my_env.version}'\r\n",
        "    )\r\n",
        "else:\r\n",
        "    my_env = ml_client.environments.get(name=ENV_NAME, version=ENV_VER)\r\n",
        "\r\n",
        "    print(\r\n",
        "        f'Environment with name {my_env.name} is found in workspace, '\r\n",
        "        f'the environment version is {my_env.version}'\r\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655368522450
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create components (pipeline steps)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import CommandComponent\r\n",
        "from azure.ai.ml import Input, Output\r\n",
        "\r\n",
        "data_prep_comp = CommandComponent(\r\n",
        "    name='stock_pred_data_prep',\r\n",
        "    display_name='Preprocess data for training',\r\n",
        "    description='reads raw price data, normalize and split the data',\r\n",
        "    inputs={\r\n",
        "        'data': Input(type='uri_folder', mode='ro_mount'),\r\n",
        "        # the inputs below will cause error \"Input string was not in a correct format\"\r\n",
        "        # 'test_ratio': Input(type='number', default=TEST_RATIO),\r\n",
        "        # 'window': Input(type='number', default=WINDOW)\r\n",
        "    },\r\n",
        "    outputs={\r\n",
        "        'scaler': Output(type='uri_file'),\r\n",
        "        'train_data_x': Output(type='uri_file'),\r\n",
        "        'train_data_y': Output(type='uri_file'),\r\n",
        "        'test_data_x': Output(type='uri_file'),\r\n",
        "        'test_data_y': Output(type='uri_file')\r\n",
        "    },\r\n",
        "    # TODO: reorganize code to minimize the code context\r\n",
        "    code='.',\r\n",
        "    command='''PYTHONPATH=$PYTHONPATH:$(pwd) \\\r\n",
        "               python azure_pipeline/preproc_data/preproc_data.py \\\r\n",
        "                   --data=${{inputs.data}} --test_ratio=0.2 \\\r\n",
        "                   --window=50 \\\r\n",
        "                   --scaler=${{outputs.scaler}} \\\r\n",
        "                   --train_data_x=${{outputs.train_data_x}} --train_data_y=${{outputs.train_data_y}} \\\r\n",
        "                   --test_data_x=${{outputs.test_data_x}} --test_data_y=${{outputs.test_data_y}}\r\n",
        "            ''',\r\n",
        "    environment=f'{my_env.name}:{my_env.version}'\r\n",
        ")\r\n",
        "\r\n",
        "data_prep_comp = ml_client.components.create_or_update(data_prep_comp)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655373351007
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_comp = CommandComponent(\r\n",
        "    name='stock_pred_model_train',\r\n",
        "    display_name='Train model',\r\n",
        "    description='train model and test model',\r\n",
        "    inputs={\r\n",
        "        'scaler': Input(type='uri_file'),\r\n",
        "        'train_data_x': Input(type='uri_file'),\r\n",
        "        'train_data_y': Input(type='uri_file'),\r\n",
        "        'test_data_x': Input(type='uri_file'),\r\n",
        "        'test_data_y': Input(type='uri_file')\r\n",
        "    },\r\n",
        "    outputs={\r\n",
        "        'model': Output(type='uri_folder'),\r\n",
        "        'tensorboard': Output(type='uri_folder')\r\n",
        "    },\r\n",
        "    code='.',\r\n",
        "    command='''PYTHONPATH=$PYTHONPATH:$(pwd) \\\r\n",
        "               python azure_pipeline/train_model/train_model.py \\\r\n",
        "                   --window=50 --epochs=15 --batch=20 \\\r\n",
        "                   --scaler=${{inputs.scaler}} \\\r\n",
        "                   --train_data_x=${{inputs.train_data_x}} --train_data_y=${{inputs.train_data_y}} \\\r\n",
        "                   --test_data_x=${{inputs.test_data_x}} --test_data_y=${{inputs.test_data_y}} \\\r\n",
        "                   --model=${{outputs.model}} \\\r\n",
        "                   --tensorboard=${{outputs.tensorboard}}\r\n",
        "            ''',\r\n",
        "    environment=f'{my_env.name}:{my_env.version}'\r\n",
        ")\r\n",
        "\r\n",
        "train_comp = ml_client.components.create_or_update(train_comp)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655431384992
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the pipeline from components"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input, Output\r\n",
        "\r\n",
        "@dsl.pipeline(\r\n",
        "    compute=COMPUTE_TARGET_NAME,\r\n",
        "    description='Stock prediction lstm model training pipeline',\r\n",
        ")\r\n",
        "def model_train_pipeline(\r\n",
        "    pipeline_data_input\r\n",
        "):\r\n",
        "    data_prep_job = data_prep_comp(\r\n",
        "        data=pipeline_data_input\r\n",
        "    )\r\n",
        "\r\n",
        "    train_job = train_comp(\r\n",
        "        scaler=data_prep_job.outputs.scaler,\r\n",
        "        train_data_x=data_prep_job.outputs.train_data_x,\r\n",
        "        train_data_y=data_prep_job.outputs.train_data_y,\r\n",
        "        test_data_x=data_prep_job.outputs.test_data_x,\r\n",
        "        test_data_y=data_prep_job.outputs.test_data_y\r\n",
        "    )\r\n",
        "\r\n",
        "    return {\r\n",
        "        'scaler': data_prep_job.outputs.scaler,\r\n",
        "        'model': train_job.outputs.model\r\n",
        "    }"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655431386886
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import webbrowser\r\n",
        "\r\n",
        "data_input = ml_client.data.get(DATA_NAME, DATA_VER)\r\n",
        "\r\n",
        "pipeline = model_train_pipeline(\r\n",
        "    pipeline_data_input=Input(type='uri_folder', path=data_input.path)\r\n",
        ")\r\n",
        "\r\n",
        "pipeline_job = ml_client.jobs.create_or_update(\r\n",
        "    pipeline,\r\n",
        "    experiment_name=EXPERIMENT_NAME\r\n",
        ")\r\n",
        "\r\n",
        "# open the pipeline in web browser\r\n",
        "webbrowser.open(pipeline_job.services['Studio'].endpoint)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1655431392984
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}